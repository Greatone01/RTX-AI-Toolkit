
# llama.cpp deployment 
This guide demonstrates converting 

Convert model checkpoints generated by RTX AI Toolkit for deployment using the llama.cpp library. 

## 0. Pre-requisites


## 1. LoRA Adapter inference


## 2. Convert checkpoint to GGML